{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/EAkeweje/GEOMETRIC-LEARNING-FOR-FLOWS-IN-POROUS-SYSTEMS/blob/main/Updated%20LS-based%20Algorithm%20(with%20sensor%20network).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWzbbflKGQWI",
    "outputId": "301b8dae-313d-4688-a920-208a6ae76b07"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LL-F3vzQGLmS",
    "outputId": "5005310d-50de-4dd6-c009-16e595976fe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Skoltech/Research/GDL\n"
     ]
    }
   ],
   "source": [
    "#Ignore this cell. \n",
    "#for access to data files\n",
    "%cd /content/drive/MyDrive/Skoltech/Research/GDL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1cuI4Qzbecga"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import PIL\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import time\n",
    "import cv2\n",
    "import random\n",
    "import glob\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YzDSsfayKEYk",
    "outputId": "5a40a4cc-afd5-4941-ce0c-03af8c00c629"
   },
   "outputs": [],
   "source": [
    "#####custom functions########\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.getcwd()+'/scripts')\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "AnXf18moZkTy",
    "outputId": "bb164da1-9d19-4905-b716-63e4d3701d37"
   },
   "outputs": [],
   "source": [
    "##visualization of pore system\n",
    "'''\n",
    "Change directory to any pore image. The function, gen_pore_array, converts the pore image to pore array.\n",
    "If you choose to use a pore array then use\n",
    "pore_array = 'path_to_pore array'\n",
    "'''\n",
    "pore_array = utils.gen_pore_array(\"./Dataset/Fluid Flow Simulation/1.png\")\n",
    "plt.imshow(pore_array,'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Q8LaMz_GD18a"
   },
   "outputs": [],
   "source": [
    "## Custom fluid flow data object\n",
    "class FluidDatasetPlus(Dataset):\n",
    "    \"\"\"\n",
    "    Fluid in porous media dataset.\n",
    "    This pytorch dataset object is an extension of FluidDataset.\n",
    "    While the earlier version only supports randomly chosen sensor (gauge) positions, \n",
    "    this version allows for specification of gauge positions. This is more applicable where the objective is to optimize the sensor (gauge) placement.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_path, root_dir, ks, num_gauge = 0, gauge_pos = None, rnd_seed = 42):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            img_path (string): Path to the porous structure image.\n",
    "            root_dir (string): Directory with all the velocity data.\n",
    "            ks (int): coarse graining grid size. If no coarse graining is required, set ks to 1\n",
    "            num_gauge (int): number of sensors\n",
    "            gauge_pos (list): list of sensor position turples (x,y)\n",
    "        \"\"\"\n",
    "        self.img_path = img_path\n",
    "        self.ks = ks\n",
    "        self.root_dir = root_dir\n",
    "        self.num_gauge = num_gauge\n",
    "\n",
    "        ##get pore image array\n",
    "        an_image = PIL.Image.open(self.img_path)\n",
    "        image_sequence = an_image.getdata()\n",
    "        image_array = np.array(image_sequence)/255\n",
    "        k = np.asarray(an_image)[:,:,0]/255\n",
    "        #adjustment so that the pore spaces are mapped to 0 and the solid immovable parts mapped to 1\n",
    "        self.pore_array = np.ones_like(k) - k\n",
    "        #get list velocity data\n",
    "        self.vel_data = sorted(glob.glob(self.root_dir+'/*.dat'))\n",
    "        ##coarse grain the system\n",
    "        self.CG_array = utils.coarse_grain(np.rot90(self.pore_array), self.ks)\n",
    "        #'install' sensors at pore walls... get the wall boundaries\n",
    "        #To condition same condition as that used for the graphing image\n",
    "        CG_array = np.where(self.CG_array <= self.ks**2/2, 0, 1)\n",
    "        #get total space from working array\n",
    "        self.total_space = utils.get_total_space(CG_array)\n",
    "        #if gauge positions not given, pick gauge positions randomly from pore walls\n",
    "        if not gauge_pos:\n",
    "          assert self.num_gauge != 0, \"Since gauge_pos = None, ensure to specify the number of gauges the program should use. Set gauge > 0\"\n",
    "          boundary_points = utils.get_bounds(1-CG_array)\n",
    "          #random select gauge spots\n",
    "          random.seed(rnd_seed)\n",
    "          self.gauge_space = random.sample(boundary_points, self.num_gauge)\n",
    "        else:\n",
    "          #check if no sensor is placed on pore solid\n",
    "          check = [_ in self.total_space for _ in gauge_pos]\n",
    "          assert all(check), f\"Adjust gauge_pos. The sensor positions in the following indices are not positioned in a pore space: {[i for i, x in enumerate(check) if x == False]}\"\n",
    "          self.gauge_space = gauge_pos\n",
    "          self.num_gauge = len(gauge_pos)\n",
    "        # assert self.num_gauge == self.gauge_space, 'Number of guages generated is not equal to the number specified'\n",
    "        #identify the no remaining no gauge spots (to estimate)\n",
    "        self.no_gauge_space = copy.deepcopy(self.total_space)\n",
    "        dup_sensor = list()\n",
    "        for b_ in self.gauge_space:\n",
    "          try:\n",
    "            self.no_gauge_space.remove(b_)\n",
    "          except:\n",
    "            dup_sensor.append(b_)\n",
    "        for b_ in dup_sensor:\n",
    "          self.gauge_space.remove(b_)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.vel_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        #get velocity field data\n",
    "        f = np.loadtxt(self.vel_data[idx])\n",
    "        f = np.reshape(f,(256,256,2))\n",
    "        f = np.rot90(f)\n",
    "        #coarse graining velocity data\n",
    "        CG_f_0 = utils.coarse_grain(f[:,:,0],self.ks)/(self.ks*self.ks)\n",
    "        CG_f_1 = utils.coarse_grain(f[:,:,1],self.ks)/(self.ks*self.ks)\n",
    "        #partitions velocity data\n",
    "        vel_x_ngs = [CG_f_0[i] for i in self.no_gauge_space] #velocity (x-dimension) at no sensor\n",
    "        vel_y_ngs = [CG_f_1[i] for i in self.no_gauge_space] #velocity (y-dimension) at no sensor\n",
    "        vel_x_gs = [CG_f_0[i] for i in self.gauge_space] #velocity (x-dimension) from sensor\n",
    "        vel_y_gs = [CG_f_1[i] for i in self.gauge_space] #velocity (y-dimension) from sensor\n",
    "        \n",
    "        return torch.tensor([vel_x_gs,vel_y_gs]), torch.tensor([vel_x_ngs,vel_y_ngs]) #returns sensor data (tensor), no sensor data (tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "id": "XMM1e1h3Wa0M"
   },
   "outputs": [],
   "source": [
    "##LS solver\n",
    "class LSReconstrutor():\n",
    "  def __init__(self, dataset, data_split = 0.3, shuffle = True, seed = 42):\n",
    "\n",
    "    self.data_split = data_split\n",
    "    self.shuffle = True\n",
    "    self.data = dataset\n",
    "    self.seed = seed\n",
    "\n",
    "    dataset_size = len(self.data)\n",
    "    indices = list(range(dataset_size))\n",
    "    split = int(np.floor(self.data_split * dataset_size))\n",
    "    if self.shuffle :\n",
    "        np.random.seed(seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "    # Creating PT data samplers and loaders:\n",
    "    train_sampler = SubsetRandomSampler(train_indices, torch.random.manual_seed(seed))\n",
    "    valid_sampler = SubsetRandomSampler(val_indices, torch.random.manual_seed(seed))\n",
    "    #Creating dataloaders\n",
    "    self.train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "    self.validation_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)\n",
    "\n",
    "  def fit(self):\n",
    "    #(training) data loading\n",
    "    for i, (x,y) in enumerate(self.train_loader):\n",
    "      if i == 0:\n",
    "        output_stack = y\n",
    "        input_stack = x\n",
    "      else:\n",
    "        output_stack = torch.cat([output_stack,y])\n",
    "        input_stack = torch.cat([input_stack,x])\n",
    "\n",
    "    #vectorization of data\n",
    "    output_dim = output_stack.shape[0]\n",
    "    input_dim = input_stack.shape[0]\n",
    "    output = output_stack.view(output_dim,-1).T\n",
    "    input = input_stack.view(input_dim,-1).T\n",
    "\n",
    "    #compute coefficient matrices\n",
    "    self.coef_mat = output @ torch.linalg.pinv(input)\n",
    "    \n",
    "    return self.coef_mat\n",
    "\n",
    "  def predict(self, error_type = None):\n",
    "    #Inference on validation data\n",
    "    '''\n",
    "    pred = A @ X; \n",
    "    where A = reconstruction operator, X = sensor measurement\n",
    "    Also Computes the error; limited to NME, R2 and NFE.\n",
    "    '''\n",
    "    for i, (x,y) in enumerate(self.validation_loader):\n",
    "      x_dim = x.shape[0]\n",
    "      y_dim = y.shape[0]\n",
    "      #vectorize validation each snapshot\n",
    "      x = x.view(x_dim,-1).T\n",
    "      y = y.view(y_dim,-1).T\n",
    "      if i == 0:\n",
    "        target_stack = y.T\n",
    "        pred_stack = (self.coef_mat @ x).T\n",
    "      else:\n",
    "        target_stack = torch.cat([target_stack,y.T])\n",
    "        pred_stack = torch.cat([pred_stack, (self.coef_mat @ x).T])\n",
    "\n",
    "    self.target = target_stack\n",
    "    self.pred = pred_stack\n",
    "\n",
    "    #losses\n",
    "    self.NME = self.NME_loss()\n",
    "    self.NFE = self.NFE_loss()\n",
    "    self.r2 = self.r2_loss()\n",
    "\n",
    "    return self.target, self.pred #returns groundtruth and prediction\n",
    "\n",
    "  #scorings\n",
    "  def NME_loss(self):\n",
    "    error = torch.linalg.norm(self.target - self.pred)/torch.linalg.norm(self.target)\n",
    "    return error\n",
    "    \n",
    "  def r2_loss(self):\n",
    "    target_mean = torch.mean(self.target)\n",
    "    ss_tot = torch.sum((self.target - target_mean) ** 2)\n",
    "    ss_res = torch.sum((self.target - self.pred) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2\n",
    "\n",
    "  def NFE_loss(self):\n",
    "    target = self.target - self.target.mean(dim =0)\n",
    "    pred = self.pred - self.target.mean(dim =0)\n",
    "    error = torch.linalg.norm(target - pred)/torch.linalg.norm(target)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "gQF-XWJXhTqh"
   },
   "outputs": [],
   "source": [
    "#Helper function to get node positions\n",
    "def get_node_pos(G, node_list):\n",
    "  '''\n",
    "  inputs:::\n",
    "  G: nx Graph\n",
    "  node_list (list): A list of nodes to place gauges\n",
    "\n",
    "  return:::\n",
    "  A list of node position in the porous structure\n",
    "  '''\n",
    "  pos = []\n",
    "  for i in node_list:\n",
    "    pos.append(G.nodes(data = 'node_pos')[i])\n",
    "  return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "EziDvrQchO8b"
   },
   "outputs": [],
   "source": [
    "#get sensor graph\n",
    "ks = 2 #coarse_graining grid size\n",
    "G = nx.read_gpickle(f\"pore_network_0{ks}.gpickle\")\n",
    "\n",
    "#select nodes\n",
    "nodes = random.sample(list(np.arange(310)), 100)\n",
    "\n",
    "#extract sensor (nodes) positions\n",
    "gauge_pos = get_node_pos(G, nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8t5KrR8hEVJi",
    "outputId": "21350acc-379f-45dc-ed98-4a50908a371f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 100 nodes\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "try:\n",
    "  dataset = FluidDatasetPlus(img_path=\"./Dataset/Fluid Flow Simulation/1.png\",\n",
    "                       root_dir = \"./Dataset/Fluid Flow Simulation\",\n",
    "                       ks = ks, gauge_pos = gauge_pos)\n",
    "except AssertionError:\n",
    "  if (29, 71) in gauge_pos:\n",
    "    gauge_pos.remove((29, 71))\n",
    "  if (109, 36) in gauge_pos:\n",
    "    gauge_pos.remove((109, 36))\n",
    "  dataset = FluidDatasetPlus(img_path=\"./Dataset/Fluid Flow Simulation/1.png\",\n",
    "                             root_dir = \"./Dataset/Fluid Flow Simulation\",\n",
    "                             ks = ks, gauge_pos = gauge_pos)\n",
    "\n",
    "print(f'Selected {dataset.num_gauge} nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1xcqSusvfCIB",
    "outputId": "bfe42732-08e3-4b3a-b5bf-516bd239ceb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0303)\n"
     ]
    }
   ],
   "source": [
    "LS = LSReconstrutor(dataset)\n",
    "LS.fit()\n",
    "LS.predict()\n",
    "print(LS.NME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ai2ocblInp7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Updated Least Squares on porous media (from graph nodes).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
